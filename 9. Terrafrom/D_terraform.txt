                  
							TERRAFORM  (terraform -version)
							==========
1. What is terraform
-> Terraform is an open-source infrastructure as code software tool that enables you to safely and predictably create, change, and improve cloud infrastructure and resources in a declarative way.
-> resources: Create virtual m/c, Virtual network, Storages resource, providers using the advantage at once. We can reuse file to recreate things again and again.
-> Used to automate various infrastructure tasks.
 
** Provisioning: Configuration activities that happen after the resource is created. 
-> It may involve some file operations, executing CLI commands, or even executing the script. Once the resource is successfully initialized, it is ready to accept connections.

Q. Disadvantages of terraform:
1. No automatic rollback, at a group it will create and it will delete at a group
2. Everyone can access the files in terraform module.
3. Expensive enterprise plan.
4. Security of â€œstate filesâ€ is a concern because managing the resources is impossible if the terraform state is ever lost.
5. Itâ€™s complicated while using local files.
6. It does not support any revert function for wrong/invalid changes to resources.(no automatic roll back)
7. Terraform is difficult to debug.
8. Difficult to operate the existing stacks. 
9. It does not contain GUI.

Q. Challenges in terraform
-> Security
-> Automatic roll back 
-> Shared access to state file and its encryption. 
-> Terraform versions. 
-> Code and Terraform Plan Review within team
-> Terraform Pull Request Automation

Q. What are the features of Terraform enterprise?
-> Below are some very useful features of Terraform cloud to provide better collaboration, management and scalability:
â— Remote execution: Ability to run Terraform configurations and apply changes from a remote machine or environment. 
â— Terraform cloud workspaces: Formerly known as Terraform Enterprise (TFE) Workspaces, is a feature of Terraform Cloud, which is HashiCorp's managed service for running Terraform in the cloud. Terraform Cloud Workspaces provide a way to organize, manage, and collaborate on Terraform configurations in a shared environment.
â— Remote state management: practice of storing the Terraform state file in a remote location rather than locally on your development machine. The state file is a critical component in Terraform as it contains the mapping between the infrastructure defined in your configuration files and the real resources provisioned in the cloud or on-premises. 
â— Version control integration and triggers.
â— CLI integration. 
â— Private registry.
â— Access Control & Governance.
â— Sentinel policies & Cost estimation: essential features in Terraform that help enforce governance and control costs in your infrastructure-as-code (IaC) workflows.

--------------------------------------------------------------------------------------------------------------------------------------------
Q. Workspace: The place where we execute terraform command.
-> Workspaces in the Terraform CLI refer to separate instances of state data inside the same Terraform working directory.
-> Terraform starts with a single, default workspace named default that you cannot delete.
Usage: terraform workspace
$$ terraform workspace show
  new, list, show, select and delete Terraform workspaces.
ubuntu@ip-172-31-27-248:~/terraform/s3$

Q. Stages of terraform cycle in terraform/ Terraform workflow:
1. Init/Write - Author infrastructure as code
-> Used to initialize a Terraform configuration in a directory. 
-> When you start working on a new Terraform project or if you update the providers or backend configurations in your existing project, you need to run terraform init to set up the necessary plugins and backend settings.
-> During initialization, Terraform downloads the required providers (plugins that interact with cloud providers like AWS, Azure, Google Cloud, etc.) and sets up the backend configuration for state storage. 
-> The backend is where Terraform stores the state file, which is crucial for keeping track of the actual state of your infrastructure.

2. Plan - Preview changes before applying.
-> Used to create an execution plan for your infrastructure changes. When you make modifications to your Terraform configuration files (e.g., add or update resources, change configurations), running terraform plan will examine the changes and determine what actions need to be taken to reach the desired state.
-> Highlights additions, modifications, and deletions in the infrastructure. 
-> The output also includes information about any potential errors, missing dependencies, or other issues that Terraform identifies during planning.
-> Helps prevent unintended changes.

3. Apply - Provision reproducible infrastructure. (If the apply failed, the run ends in the Apply Errored state)
-> Used to apply the changes planned in the previous step. When you run terraform apply, Terraform will read the execution plan and begin the process of creating, updating, or destroying resources to reach the desired state specified in your configuration.
-> Terraform will prompt you to confirm the planned actions before proceeding with any changes. Review the execution plan carefully to ensure that you understand the impact of the changes on your infrastructure.
ğŸ“Œ To auto-approve and skip confirmation:
terraform apply -auto-approve

4. Destroy - (Delete Infrastructure)
-> Destroys all resources defined in the Terraform configuration.
-> Useful for tearing down environments (e.g., deleting test infrastructure).

COMMANDS USED IN TERRAFORM:
---------------------------
-> terraform state mv [options] SOURCE DESTINATION: merge two state Moving resources from one to the other using
ğŸ‘‰ Why? If you don't move the state, Terraform will destroy the old instance and create a new one!

Deprecated:
1. terraform refresh -> terraform -refresh-only
2. terraform taint  ->  terraform apply -replace="aws_instance.web"

-> terraform refresh: Refreshes state file, Detect manual changes made outside Terraform, Sync state without modifying infrastructure [Deprecated]
-> terraform plan -refresh-only: Updates Terraform state (.tfstate), Does not modify .tf files or create a new execution plan, Shows differences between actual and recorded state
-> terraform apply -refresh-only: Updates the .tfstate file, Does not modify infrastructure

-> terraform show: Provide human-readable output from a state or plan file. 
$$ terraform show:	Displays the current state (terraform.tfstate)
$$ terraform show tfplan:	Shows details of a saved execution plan

-> terraform graph: Generate a graph representation / visual representation of either a configuration or execution plan
1. Generate a Terraform Graph: $$ terraform graph > graph.dot
2. Convert Graph to an Image: $$ dot -Tpng graph.dot -o graph.png
3. Generate a Cleaned-Up Graph: $$ terraform graph | dot -Tsvg > graph.svg

-> terraform validate: it will validate syntax of terraform files/command.
-> terraform destroy: to terminate resources (inverse of terraform apply)
-> terraform init -upgarde: to update plugins in terraform  
-> terraform fmt: Formats the Terraform files to make them consistent and easy to read (rewrite configuration files in canonical styles and format)
-> terraform state: Provides information about the "current state of the infrastructure resources" managed by Terraform.
-> terraform output: displays the output values of the infrastructure resources created by Terraform.
-> terraform import: imports existing infrastructure resources into Terraform state so that they can be managed using Terraform.
-> terraform workspace: to create and manage multiple workspaces, which are isolated environments for managing infrastructure resources.

-> terraform taint: command informs Terraform that a particular object has become degraded or damaged. [Depreicated]
-> terraform apply -replace: to recreate the resource.


Q. Duplicate resource error in terraform?
-> A duplicate resource error occurs in Terraform when you define the same resource with the same name more than once in your configuration.
-> Possible causes of this could be: you (or someone else ) have executed your Terraform code/.tf file and you don't have a shared / updated state.
-> to update: terraform refresh
ğŸ”¹ Causes & Fixes:
1.  Cause 1: Duplicate Resource Block
2. Cause 2: Duplicates in Multiple Files
3. Cause 3: Duplicate Resource in Terraform State: If you manually modified Terraform state, you might have duplicates
4. Cause 4: Using terraform import Without Defining the Resource: If you imported an existing resource without defining it in Terraform, Terraform might think itâ€™s a duplicate.


ğŸ”¹ Terraform directory: The working directory is where you store all your configuration files, state files, and modules. This directory contains the necessary files for Terraform to manage your infrastructure.
my-terraform-project/
â”‚â”€â”€ main.tf            # Main configuration file[infrastructure resources, like EC2 instances, databases, networking, etc.]
â”‚â”€â”€ variables.tf       # Input variables [e.g., the region, instance type, etc]
â”‚â”€â”€ outputs.tf         # Output values [like instance IP addresses, URLs, etc]
â”‚â”€â”€ provider.tf        # Provider configuration [(e.g., AWS, GCP, Azure) ]
â”‚â”€â”€ terraform.tfvars   # Variable values
â”‚â”€â”€ versions.tf        # Terraform & provider version constraints
â”‚â”€â”€ backend.tf         # Remote backend configuration
â”‚â”€â”€ modules/           # Reusable Terraform modules
â”‚   â”œâ”€â”€ networking/    # Example module: VPC, subnets
â”‚   â”œâ”€â”€ compute/       # Example module: EC2, VM
â”‚â”€â”€ environments/      # Separate configurations for dev/staging/prod
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â”œâ”€â”€ terraform.tfvars
â”‚   â”œâ”€â”€ prod/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ variables.tf
â”‚   â”‚   â”œâ”€â”€ terraform.tfvars
â”‚â”€â”€ .terraform/        # Terraform state and cache (generated after init)
â”‚â”€â”€ terraform.tfstate  # Terraform state file (DO NOT EDIT manually)
â”‚â”€â”€ terraform.tfstate.backup # Backup state file
â”‚â”€â”€ .terraform.lock.hcl # Dependency lock file

** .terraform Directory: This is a hidden directory where Terraform stores provider plugins and modules that it downloads. You don't need to modify or interact with this directory directly, as Terraform manages it for you.

--------------------------------------------------------------------------------
-> Terraform Components: Terraform Core and Terraform Plugins
1. Terraform Core
-> Terraform Core is like the "brain" of Terraform. It does the following:
ğŸ‘‰ Reads and processes configuration files: Terraform Core takes the instructions you've written (in .tf files) and works out what resources you want to create, update, or destroy.
ğŸ‘‰ Creates a resource graph: It figures out how all the resources you defined are connected (for example, which resources depend on others).
ğŸ‘‰ Manages the state: It tracks the current state of your infrastructure, so it knows what has been created and what needs to change.
ğŸ‘‰ Handles Terraform lifecycle: The "lifecycle" is the sequence of steps Terraform goes through:
-- terraform init: Prepares Terraform to run, setting things up like downloading necessary plugins.
-- terraform plan: Shows you what changes Terraform will make to your infrastructure.
-- terraform apply: Actually makes those changes to your infrastructure.
-> In short, Terraform Core is in charge of managing the entire process of planning and applying changes to your infrastructure.

2. Terraform Plugins
-> Terraform Plugins are like "helpers" that Terraform uses to interact with different services (like AWS, Azure, Google Cloud, etc.). These are separate programs that perform specific tasks.
-> Each plugin is specific to a service: For example, there's a plugin for AWS, another for Azure, etc. 
-> Each plugin knows how to create, update, and delete resources on the respective cloud provider.
-> Plugins are written in Go: The code for these plugins is written in the Go programming language. Each plugin is a separate executable file that communicates with Terraform Core.
-> They talk to Terraform Core: Plugins use a special communication method called RPC (Remote Procedure Call) to talk to Terraform Core and carry out tasks like creating an EC2 instance or an S3 bucket.

** Data sources in Terraform are used to get information about resources external to Terraform, and use them to set up your Terraform resources. 
1ï¸âƒ£ Example Use Cases
-- Get an existing AWS AMI ID for an EC2 instance.
-- Retrieve existing VPC details.
-- Fetch information from cloud providers (e.g., AWS, Azure, GCP).
-- Reference Terraform remote state (from another Terraform workspace).

---------------------------------------------------------------------------------
** (Tfstate) state in terraform : condition of a resource is called state in a given time. 

ğŸ”¹ Terraform Modules
-> A Terraform module is a collection of .tf files that help you reuse and organize infrastructure code.
âœ… Helps modularize infrastructure.
âœ… Improves code reusability.
âœ… Allows for consistent deployments.

-> Terraform modules are a way to organize and encapsulate sets of resources with a specific purpose or functionality.
-> All configuration files of terraform are saved here publicly in a single directory so that everyone can access it.
-> Even a simple configuration consisting of a single directory with one or more ".tf" file is a module.
-> Modules in Terraform are written in HashiCorp Configuration Language (HCL) or, in some cases, in JSON.
-> When you run Terraform commands directly from such a directory, it is considered the root module.to reuse we are creating .tf instead of normal file, if we delete it, we can not recreate other file using it. (if u delete in local and backend also)
-> These modules are designed to be instantiated multiple times and can be parameterized, allowing you to customize the resources created based on your specific needs.
-> Terraform modules help in managing infrastructure as code and provide a convenient way to structure and maintain Terraform configurations for complex deployments.

** Types of modules: Root, child and Published
-> Child Modules: A module that has been called by another module is often referred to as a child module.(which calls is called parent, root module)

1. Root Module:
-> The "Root module" is the main entry point of a Terraform configuration. It represents the top-level directory where you typically define your infrastructure resources and other Terraform components. 
-> The root module can contain various Terraform configuration files (.tf files) that define the resources to be provisioned.
-> The root module typically contains the provider configurations (e.g., AWS, Azure, Google Cloud) and may also include variable definitions, data sources, and outputs. 

2. Child Module:
-> A "Child module" is a self-contained Terraform configuration that can be used as a building block within the root module or other child modules. Child modules encapsulate specific functionality or resources, allowing you to create reusable and modular configurations.
-> By creating child modules, you can abstract complex configurations into simpler components, making your Terraform code more organized and maintainable. Child modules can have their own variables, outputs, and resource definitions.

3. Published Module:
-> A "Published module" refers to a reusable Terraform configuration that is shared and made available for use by other users or teams. 
-> Once you create a child module or a set of related modules that have value beyond a specific project, you can publish them to a public or private module registry.

Q. What is the main TF file in Terraform?
-> main.tf will contain the main set of configuration for your module. 
-> variables.tf will contain the variable definitions for your module.
-> You can also create other configuration files and organize them however makes sense for your project.

-------------------------------------------------------------------------------
Q. What are variables in terraform and types of variables?
-> variables are used to define and pass values dynamically to configuration files. 
-> They provide a way to make your Terraform configurations more flexible and reusable. 
-> Instead of hard-coding values directly into your code, you can use variables to pass values from the command line, environment variables, or external configuration files.

4ï¸âƒ£ Ways to Pass Input Variables
1. Interactive 
2. Command line	(First priority): $$ terraform apply -var="instance_type=t3.medium"
3. Environment Variables: $$ export TF_VAR_instance_type="t3.medium"
4. terraform.tfvars: $$ instance_type = "t3.medium"
5. Auto .TF var file 	(Second priority)

ğŸ”¹ Types of Variables in Terraform
1. Input Variables:
-> To declare the parameters that you want to accept as input when running Terraform. 
ğŸ“Œ Defined in: variables.tf or directly in main.tf.
ğŸ“Œ Types: string, number, bool, list, map, object, set, tuple.
-> They are defined in the root module or any other module, and their values can be set using command-line flags, environment variables, or by creating a "terraform.tfvars" file.
Example:
variable "region" {
  description = "The Azure region where resources will be created."
  type        = string
  default     = "East US"
}

2. Local Variables:
-> Local variables are used to define intermediate values within a module or configuration. 
-> They are not exposed as input variables and are typically used for simplifying complex expressions or for storing calculated values.
-> Can not be overridden at all.
ğŸ“Œ Purpose: Store temporary values within a module for better readability.
ğŸ“Œ Scope: Limited to the module where defined.
Example:
locals {
  subnet_prefix = "10.0.1."
  subnet_count  = 4
}

3. Output variables:
-> These will be displayed in the command-line output, and you can also use them in other Terraform configurations or scripts.
ğŸ“Œ Purpose: Displays information after running terraform apply.
output "public_ip" {
  value = aws_instance.app_server.public_ip
}

3. Environment Variables:
-> Terraform automatically picks up environment variables with the "TF_VAR_" prefix and uses them as input variables. 
-> This allows you to set variable values from the shell environment.
Example:
export TF_VAR_region="West US"

4. Data Source Values:
-> Data sources are used to retrieve information about resources that already exist outside of Terraform. 
-> You can use data sources to set variable values based on the attributes of those resources.
Example:
data "aws_vpc" "existing" {
  id = "vpc-12345678"
}
variable "vpc_id" {
  default = data.aws_vpc.existing.id
}

5. Map and List Variables:
-> Terraform allows you to use maps and lists as variable types. 
-> Maps store key-value pairs, while lists store ordered sequences of values.
Example (Map):
variable "tags" {
  type = map(string)
  default = {
    environment = "dev"
    app_name    = "my_app"
  }
}
Example (List):
variable "subnet_ids" {
  type = list(string)
  default = ["subnet-1", "subnet-2"]
}


------------------------------------------------------------------------------------
Q. What is implicit and explicit dependency?
-> In Terraform, implicit and explicit dependencies refer to the relationship between resources in a Terraform configuration.
1ï¸âƒ£ Implicit Dependency
-> An implicit dependency occurs when Terraform automatically determines that one resource requires another resource to be created first. 
-> For example, if you have a resource that creates an Amazon S3 bucket, and another resource that uploads an object to that S3 bucket, Terraform will automatically create the S3 bucket before uploading the object, even if this relationship is not explicitly stated in the configuration.

2ï¸âƒ£ Explicit Dependency (depends_on)
-> An explicit dependency, on the other hand, is a relationship between resources that is explicitly defined in the Terraform configuration. 
-> For example, you can use the "depends_on" argument in Terraform to specify that one resource depends on another resource. 
-> This makes it easier for Terraform to determine the order in which resources should be created, and can also make the relationships between resources more transparent.
-> In general, Terraform encourages the use of explicit dependencies, as they make the relationships between resources more clear and easier to understand.

--------------------------------------------------------------------------------
-> Starting Terraform 1.4, null resources are deprecated and can be replace by terraform_data resource. They offer the same capabilities but the latter is built-in and doesn't need to be explicitly added to the required providers block.

ğŸ”¹ Null Resource
-> A null_resource is a special Terraform resource that doesnâ€™t create any infrastructure but allows you to execute provisioners, run scripts, or create dependencies between resources.
-> You can think of the Null Resource as a placeholder for "something to do" without actually provisioning or managing real resources like virtual machines, databases, or networks.

Key Points about Null Resource:
1. It doesn't create any actual infrastructure (like an EC2 instance, S3 bucket, etc.).
2. It's often used to trigger actions or run commands.
3. It can be used for provisioning tasks, such as running scripts, sending notifications, etc.
4. It works like a regular Terraform resource but doesn't correspond to anything physical in your infrastructure.

** Example of a Null Resource:
-> Let's say you want to run a shell script whenever a specific resource is created or updated. You can use the null_resource to trigger the script.

resource "null_resource" "config_change" {
  triggers = {
    config_version = "v1.2.3"
  }

  provisioner "local-exec" {
    command = "echo 'Configuration changed!'"
  }
}

---------------------------------------------------------------------------------------
ğŸ”¹ Backend in Terraform
-> The "Backend" in Terraform is where the state of your infrastructure is kept and how Terraform interacts with it. 
-> In Terraform, the backend is responsible for storing the state of the infrastructure and managing how Terraform communicates with various services to execute operations. 
-> The backend allows Terraform to track the resources it creates, updates, and destroys, providing a central place for managing and storing the state file (terraform.tfstate).

Q. What are the two types of backends in Terraform?
-> Based on this, Terraform backends are classified into two types.
a. Enhanced Backend â€“ Additional operations like plan, apply, etc. on remote.
b. Standard backend â€“ Simple State file storage and lock facility.


Q. What is .tfstate file and its backend process?
-> The ".tfstate" file is a state file used by Terraform to keep track of the current state of your infrastructure. Itâ€™s a critical component of Terraform because it allows Terraform to understand:
	* What resources are managed by Terraform.
	* The current settings and attributes of those resources.
	* What changes are required when you run terraform apply.

Terraform Backend and its Role in State Management: 
---------------------------------------------------
-> A backend in Terraform determines how and where the state file is stored. It plays a critical role in storing, sharing, and locking the .tfstate file, especially in multi-user or large-scale environments.

-> Types of Backends in Terraform:
1. Local Backend (Default):
âœ” The .tfstate file is stored on your local machine in the directory where you run Terraform.
âœ” Suitable for small, single-user setups.
âœ” Disadvantages: Not ideal for collaboration or large-scale projects because the state file isn't shared, and it may be prone to data loss if something happens to your local machine.

2. Remote Backends:
âœ” Store the .tfstate file in a remote storage system, such as Amazon S3, Azure Blob Storage, Google Cloud Storage, etc.
âœ” Remote backends allow for collaboration by enabling multiple users to share the same state file, and it also supports state locking to prevent conflicts.

-> Use Remote Backends: Collaboration, State locking, Backup and Durability

-> Common remote backends include:
a. Amazon S3 with DynamoDB for state locking.
b. Azure Blob Storage.
c. Google Cloud Storage.
d. Terraform Cloud or Terraform Enterprise (HashiCorpâ€™s own solution).

--------------------------------------------------------------------------------------
Q. How do I create a backend in Terraform?
1. Choose Your Remote Backend Type
-> Terraform supports several backend types, including:
a. S3 (Amazon Web Services) for state storage with optional locking via DynamoDB.
b. Azure Blob Storage for Azure-based state management.
c. Google Cloud Storage for GCP-based state management.
d. Terraform Cloud or Enterprise for hosted backends.

2. Configure the Backend in the Terraform Configuration File
-> You need to define the backend configuration inside the terraform block. The backend block tells Terraform where to store the state and how to access it.

-> Example: AWS S3 Backend with DynamoDB for State Locking
-- "We configure a backend using Amazon S3 for state storage and DynamoDB for state locking" to avoid race conditions when multiple users are applying changes at the same time.

** Create the Necessary AWS Resources (if not already done):
	S3 Bucket: For storing the state file.
	DynamoDB Table: For managing state locks.

terraform {
  backend "s3" {
    bucket         = "my-terraform-state-bucket"        # Your S3 bucket name
    key            = "/my/"       # Path where the state file will be stored in the bucket
    region         = "us-west-2"                         # AWS region
    encrypt        = true              # Enable encryption at rest using AES-256 or KMS
    dynamodb_table = "my-locking-table"                 # DynamoDB table for state locking
    acl            = "private" # ACL permissions for the state file, Controls S3 Perssions
  }
}

3. Run terraform init to Initialize the Backend
-> Once you've added the backend configuration, you need to initialize Terraform using the terraform init command. This command configures your backend and sets up the state storage.

4. Work with the Backend
-> Once the backend is initialized, Terraform will use the remote state for any subsequent commands (terraform plan, terraform apply, etc.).

5. Verifying the Backend
-> You can verify that the state file is being stored in the remote backend by checking the location of your state (e.g., in the S3 bucket or the Terraform Cloud UI) and confirming that changes made in the Terraform configuration are reflected there.

-----------------------------------------------------------------------------------
ğŸ”¹ Creating a DynamoDB Table for Locking
-> Before using dynamodb_table, you must create a DynamoDB table in AWS:
aws dynamodb create-table \
    --table-name my-locking-table \
    --attribute-definitions AttributeName=LockID,AttributeType=S \
    --key-schema AttributeName=LockID,KeyType=HASH \
    --billing-mode PAY_PER_REQUEST
âœ… Now Terraform can use this table to prevent conflicts.

ğŸ”¹ Available ACL Options:
ACL Type			Description
private			Most secure â†’ Only the bucket owner can access it.
public-read		Readable by everyone (âŒ not recommended for security reasons).
public-read-write	Anyone can read/write (âš  security risk).
authenticated-read	Only AWS-authenticated users can read.

ğŸ“Œ Example of KMS encryption instead of default AES-256:
encrypt = true
kms_key_id = "arn:aws:kms:us-east-1:123456789:key/abc-def"

--------------------------------------------------------------------------------------
Q. Diff between .tf and .tfstate:
-> .tf files are used to define the desired state of the infrastructure, while .tfstate files are used to store the current state of the infrastructure managed by Terraform. 
-> The .tf files are the input to Terraform, while the .tfstate files are the output. 
-> The .tfstate files are critical to the proper functioning of Terraform, as they are used to determine what changes need to be ade to bring the infrastructure into the desired state. 

-> State file: A JSON file that stores the current state of your infrastructure.
-> Terraform state file lock: It will make sure that the state is â€œlockedâ€ if it's presently in use by another user (the second user cannot perform terraform apply)
-> At a time both person using same .tf file, one person will perform operation apply then other person can't operate.

Q. Can you merge two states in terraform?
** Merging two states involves moving resources from one to the other using "terraform state mv [options] SOURCE DESTINATION"
[a]. Note: Use the version of Terraform that matches the desired end state to perform the operations.
âœ…terraform state mv â†’ Moves resources between states.
âœ…terraform import â†’ Re-imports resources into a new state.

Q. How we recover failed terraform apply?  "Terraform import"
-> You need to restore, then need to recreate the state you lost, that or delete every object you created via Terraform and start again. 
-> Most objects have the ability to import existing objects via the "Terraform import" command.

ğŸ”¹ Why Does terraform apply Fail?
1ï¸âƒ£ Network Issues â€“ Connection lost while applying changes.
2ï¸âƒ£ State Lock Issues â€“ Another Terraform process is holding the state lock.
3ï¸âƒ£ Resource Conflicts â€“ Manually modified resources outside Terraform.
4ï¸âƒ£ Incorrect Configurations â€“ Syntax errors, missing variables, or invalid providers.
5ï¸âƒ£ Provider API Issues â€“ Terraform tries to create a resource that already exists.

ğŸ”¹ How to Recover a Failed Terraform Apply?
âœ… 1. Identify the Cause of Failure: $$ terraform apply -debug
âœ… 2. Unlock the State File (If Locked): terraform force-unlock <LOCK_ID>
âœ… 3. Refresh the Terraform State: terraform refresh / terraform plan -refresh-only
âœ… 4. Fix the Issue in Configuration: terraform validate
âœ… 5. Manually Import Partially Created Resources (If Needed): terraform import aws_instance.example i-1234567890abcdef0
âœ… 6. Retry terraform apply

------------------------------------------------------------------------------------
ğŸš¨ What If the State Is Corrupt?
-> If your state file is damaged

Q. How to Recover from a Corrupted State File?
Option 1: Copy a previous version of the state file into the same bucket.
Option 2: Permanently delete the current version of the file (i.e., the corrupted one)

ğŸ”¹ Steps to Recover from a Corrupt Terraform State File
âœ… 1. Check If You Have a State Backup: $$ mv terraform.tfstate.backup terraform.tfstate
âœ… 2. Unlock the State (If Locked): $$ terraform force-unlock <LOCK_ID>
$$ aws dynamodb delete-item --table-name my-locking-table --key '{"LockID": {"S": "abc-123"}}'
âœ… 3. Manually Repair the State File: $$ cat terraform.tfstate | jq .
âœ… 4. Recreate State Using terraform import: $$ terraform import aws_instance.my_ec2 i-1234567890abcdef0
$$ terraform plan
âœ… 5. Recover State from a Remote Backend (S3, Terraform Cloud, etc.): $$ terraform init -reconfigure
-> If S3 is used: $$aws s3 cp s3://my-terraform-backend/terraform.tfstate .
âœ… 6. Reapply Terraform Configuration: $$ terraform apply

--------------------------------------------------------------------------------------
ğŸ“Œ What is a dynamic block in Terraform?
-> A dynamic block in Terraform is used when you need to create multiple similar nested blocks dynamically, instead of manually repeating them in your configuration.
-> Where for creates repeatable top-level resources, like VNets, dynamic creates nested blocks within a top-level resource, like subnets within a VNet.

Ex1: Dynamic Block with for_each for Security Group Rules
 resource "aws_security_group" "example" {
  name = "example-sg"

  dynamic "ingress" {
    for_each = var.ingress_rules
    content {
      from_port   = ingress.value.from_port
      to_port     = ingress.value.to_port
      cidr_blocks = ingress.value.cidr_blocks
      protocol    = ingress.value.protocol
    }
  }
}

Example 2: Dynamic Block for Multiple Tags
resource "aws_instance" "example" {
  ami           = "ami-12345678"
  instance_type = "t2.micro"
  
  dynamic "tags" {
    for_each = var.tags
    content {
      key   = tags.key
      value = tags.value
    }
  }
}

------------------------------------------------------------------------------------
** Terraform providers:
-> In Terraform, a provider is a plugin that allows Terraform to interact with various services, platforms, and APIs. 
-> Providers are responsible for managing the lifecycle of resources such as creating, reading, updating, and deleting infrastructure components. 
-> A provider translates the configuration written in Terraformâ€™s declarative language into API calls that interact with the underlying infrastructure.

** Key Points:
-> Providers are the bridge between Terraform and the services it manages (like AWS, Google Cloud, Azure, Kubernetes, etc.).
-> They enable Terraform to manage resources across a wide variety of platforms and tools.
-> Each provider has its own set of resources and data sources, which are defined by the provider's API.
-> Providers are defined in the Terraform configuration using the provider block.
Ex:
provider "aws" {
  region = "us-west-2"  # Specify the AWS region (e.g., "us-east-1", "us-west-2")
}

-> Itâ€™s important to specify the version of the AWS provider in your Terraform configuration to ensure compatibility with your Terraform version and AWS API.
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 4.0"  # Specify the version you want
    }
  }
}


Q. Is provider is mandatory to give in tf file? if u give/dont give provider what will happen ?
-> A provider configuration block is required in every Terraform configuration.
** A provider in Terraform is a plugin that enables interaction with an API. 

* If not given provider: Terraform will try to use:
1. Environment Variables (such as AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and AWS_DEFAULT_REGION for AWS).
2. AWS CLI Profile (if you have an ~/.aws/credentials file or you specify the profile in the configuration).
-> In short, if the provider block is missing, Terraform will look for credentials in the environment or use default settings to authenticate.

3. When Provider Is Not Defined at All: Terraform will fail when trying to plan or apply the configuration, as it wonâ€™t know which provider to use.
Error: No provider "aws" found

----------------------------------------------------------------------------------------
** Provisioners: 
-> In Terraform, provisioners are used to execute scripts or commands on resources after they are created or modified. 
-> Provisioners are not the primary way to manage resources; they are meant for post-creation configuration.
-> Provisioners help with tasks like software installation, configuration, or executing custom scripts on the infrastructure once Terraform has finished creating the resources.

** Remote exec: provisioner invokes a script on a remote resource after it is created. 
-> This can be used to run a configuration management tool, bootstrap into a cluster, etc
** Local-exec: provisioner invokes a local executable after a resource is created. This invokes a process on the machine running Terraform, not on the resource.

1. Remote-Exec Provisioner:
-> The "remote-exec" provisioner in Terraform is used to run commands or scripts on a remote resource, typically an instance or virtual machine created by a cloud provider like AWS, Azure, or Google Cloud. 
-> The remote-exec provisioner is often used for tasks such as software installation, configuration management, or initializing resources.
-> Example of using a remote-exec provisioner in a Terraform configuration:
resource "aws_instance" "web_server" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t2.micro"

  provisioner "remote-exec" {
    inline = [
      "sudo apt-get update",
      "sudo apt-get install -y nginx",
      "sudo service nginx start",
    ]
  }
}
-> In this example, the "remote-exec" provisioner runs a series of commands on the AWS EC2 instance after it has been created. It installs the Nginx web server and starts the service.


2. Local-Exec Provisioner:
-> Executes a command on the machine where Terraform is running.. 
-> It's useful when you need to run commands or scripts locally (on the machine where Terraform is being run), such as setting up configurations or notifying other systems.
-> Example of using a local-exec provisioner in a Terraform configuration:
resource "aws_instance" "web_server" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t2.micro"

  provisioner "local-exec" {
    command = "echo 'Instance IP: ${self.public_ip}' >> instance_ips.txt"
  }
}
-> In this example, the "local-exec" provisioner runs a shell command on the machine executing Terraform. It echoes the public IP address of the AWS EC2 instance into a text file named "instance_ips.txt" in the current working directory.


3. File Provisioner:
-> Uploads files from the local machine to the remote resource. It is typically used when you need to transfer configuration files or scripts to a server.
resource "aws_instance" "example" {
  ami           = "ami-12345678"
  instance_type = "t2.micro"

  provisioner "file" {
    source      = "path/to/local/file"  # Path to the file or directory on the local machine
    destination = "/path/to/remote/file"  # Path on the remote machine where the file will be copied
  }
}

---------------------------------------------------------------------------------------
** Meta arguments:-
------------------- 
-> These are special arguments that apply to resources, modules, and other blocks in a Terraform configuration. 
-> These meta-arguments allow for controlling the behavior of resources or modules and define how Terraform interacts with the infrastructure. 
-> They are not specific to any one resource or provider, but rather have a global effect across all resources in the configuration. 
-> Its value should be an unquoted <PROVIDER>.
-> Ex: [depends_on, count, for_each, lifecycle, provider, provider_meta, timeouts]

1. lifecycle
-> The lifecycle meta-argument allows you to customize how Terraform manages the lifecycle of a resource. It includes several sub-arguments, such as:
1. create_before_destroy: Ensures that resources are created before old ones are destroyed during updates.
2. prevent_destroy: Prevents the resource from being destroyed, even if the configuration changes.
3. ignore_changes: Ignores changes to specified resource attributes during future terraform apply actions.
resource "aws_security_group" "example" {
  name        = "example-sg"
  description = "Example security group"

  lifecycle {
    prevent_destroy = true
  }
}

2. timeout:
-> The timeouts meta-argument allows you to specify timeouts for creating, updating, and deleting resources. 
-> This is useful when a resource may take a long time to provision or decommission.
resource "aws_instance" "example" {
  ami           = "ami-12345678"
  instance_type = "t2.micro"

  timeouts {
    create = "1h"
    delete = "30m"
  }
}

depends_on	Specifies explicit dependencies between resources or modules.
count		Creates multiple identical resources based on a count.
for_each	Creates multiple resources based on a map or set.
lifecycle	Customizes the lifecycle behavior of resources, such as prevent_destroy or ignore_changes.
provider	Specifies the provider to use for a specific resource or module.
timeouts	Defines timeouts for the resource creation, update, and deletion.

--------------------------------------------------------------------------------------
Q. Why do we use terraform import?
-> The terraform import command is used to bring existing infrastructure (that was not originally created using Terraform) into Terraformâ€™s state management system. 
-> This command allows Terraform to track and manage resources that were created outside of Terraform or by other means, so they can be managed alongside resources created and managed by Terraform itself.
 
## Warning: Terraform expects that each remote object is bound to only one resource address. You should import each remote object to only one Terraform resource address.
-> Terraform achieves portability by using a provider-based architecture that enables it to interact with various infrastructure resources and services in a consistent way. 
-> Each provider is responsible for managing resources on a specific platform, and Terraform abstracts away the platform-specific details, enabling users to manage infrastructure resources using a single, consistent language and set of tools.

terraform import [options] <address> <id>
address; aws_instance.my_instance

Example 1: Import an S3 Bucket
-> Suppose you have an existing AWS S3 bucket with the name my-existing-bucket and you want to import it into Terraform's state.

1. Create a resource block for the S3 bucket in your Terraform configuration file (main.tf):
resource "aws_s3_bucket" "my_bucket" {
  bucket = "my-existing-bucket"  # This name must match the actual bucket name
}

2. Import the S3 bucket using the terraform import command:
terraform import aws_s3_bucket.my_bucket my-existing-bucket


Example 2: Import an AWS EC2 Instance
-> Let's say you already have an AWS EC2 instance with the ID i-0abcd1234efgh5678, and you want to import it into Terraform's state.
1. Create a resource block in your Terraform configuration file (main.tf) to define an AWS EC2 instance:
resource "aws_instance" "my_instance" {
  ami           = "ami-0c55b159cbfafe1f0" # Example AMI ID (you will update this)
  instance_type = "t2.micro"               # Example instance type
}

2. Import the EC2 instance using the terraform import command:
terraform import aws_instance.my_instance i-0abcd1234efgh5678

-> You will need to run terraform plan to see the differences, and possibly update the configuration to match the imported resource.

---------------------------------------------------------------------------------------
** Tainted resource: The terraform taint command informs Terraform that a particular object has become degraded or damaged. 
-> Terraform represents this by marking the object as "tainted" in the Terraform state, and Terraform will propose to replace it in the next plan you create.
-> The resource is mis-configured can not be used in present lifecycle but can not be used after tainted/repaired.

$$ terraform taint aws_instance.my_instance
$$ terraform untaint aws_instance.my_instance
$$ terraform plan to see which resources are marked for destruction and recreation.

Q. Why Taint a Resource?
-> Tainting a resource can be useful in several scenarios:
1. Manual Changes: If a resource has been modified manually or outside of Terraform, you may want to taint it so that Terraform can replace it and ensure the state is consistent with the configuration.

2. Unhealthy Resource: If a resource becomes unhealthy (e.g., an EC2 instance becomes unreachable), you can taint the resource to trigger its recreation and bring it back to a healthy state.

3. Recreating a Resource for Testing: If you want to recreate a resource for testing or during troubleshooting, you can taint it to force a new creation during the next terraform apply.

4. Corrupted Resources: If Terraform detects that a resource is in an invalid state or unreachable, tainting it will allow Terraform to destroy and recreate it.

---------------------------------------------------------------------------------------
Q. Data types in terraform?
-> Terraform supports a number of types, including string, number, bool, list, map, set, object, tuple, and any.
-> string: a sequence of characters representing some text, such as â€œhelloâ€.
-> number: a numeric value. ...
-> bool: either true or false.
-> list (or tuple ): a sequence of values, like ["us-west-1a", "us-west-1c"]
-> map (or object): a group of values identified by named labels, like {name = "Mabel", age = 52}.
-> null: a value that represents absence or omission. If you set an argument of a resource to null, Terraform behaves as though you had completely omitted it 
  â€”> it will use the argument's default value if it has one, or raise an error if the argument is mandatory. 
  -> null is most useful in conditional expressions, so you can dynamically omit an argument if a condition isn't met.
-> tupple: specifying some value 

--------------------------------------------------------------------------------------
Q. How do I run Terraform locally?
-> Run Terraform plan
a. Navigate to your application infrastructure code - cd modernisation-platform-environments/terraform/environments/my-application
b. Run a Terraform init - terraform init
c. View the workspaces (you have different workspaces for your different environment accounts) - terraform workspace list
d. Select the required workspace - terraform workspace select my-application-development
e. Run a Terraform plan - terraform plan

Q. How is Terraform different from Ansible?
-> Terraform excels as a cloud infrastructure provisioning and deprovisioning tool with an IaC approach. It's a specific tool with a specific purpose.
-> Ansible offers an all-purpose, cross-domain automation solution. Both have active open source communities and well-supported downstream commercial products.
-> Ansible is configuration tool which manages resources.

Q. What are terraform actions?
-> The hashicorp/setup-terraform action is a JavaScript action that sets up Terraform CLI in your GitHub Actions workflow by: Downloading a specific version of Terraform CLI and adding it to the PATH .

Q. How can you define dependencies in Terraform?
-> You can use "depends_on" to declare the dependency explicitly. You can also specify multiple resources in the "depends on" argument, and Terraform will create the target resource after all of them have been created.

============================================================================================================
Q. How two people using two different data infrastructure using same working directory
-> it requires proper planning and coordination.
1. One approach could be to use separate Terraform workspaces for each person. Workspaces allow you to maintain multiple variations of the same infrastructure, each with its own state file. This way, each person can work on their own data infrastructure using the same working directory, and Terraform will maintain separate state files for each workspace, ensuring that each person's changes do not affect the other person's infrastructure.

2. Another approach could be to use separate directories for each person's Terraform configuration, and use a version control system like Git to manage the code. Each person would clone the repository to their own local machine, make changes to their own directory, and then push those changes to the central repository. This approach would require more coordination, as the two people would need to merge their changes and resolve conflicts, but it would allow each person to work on their own infrastructure while still using the same codebase.
-> In both cases, it's important to have a clear understanding of the infrastructure dependencies and to ensure that changes made by one person do not negatively impact the other person's infrastructure.

Q. How do we define multiple provider configurations?
-> You can optionally define multiple configurations for the same provider, and select which one to use on a per-resource or per-module basis. 
-> The primary reason for this is to support multiple regions for a cloud platform; other examples include targeting multiple Docker hosts, multiple Consul hosts, etc

---------------------------------------------------------------------------------------
Q. Terraform cloud: 
-> It is a remote environment which is optimized for terraform workflow.
-> Terraform Cloud is HashiCorp's managed service offering. 
-> It eliminates/avoids unnecessary tooling and documentation for practitioners, teams, and organizations to use Terraform in production.
-> Terraform Cloud enables infrastructure automation for provisioning, compliance, and management of any cloud, data center, and service.

Q. Why Terraform cloud:
-> Terraform allows DevOps Engineers to automate and manage the Data Center Infrastructure, the platforms, and the services that run on those platforms, all from one location, that you can reuse and share.
-> Azure cloud we are integrating with terraform.